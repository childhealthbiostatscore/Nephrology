---
title: "child_analyitic_cohort"
author: "Casey Sakamoto"
date: "2025-01-27"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggplot2)
library(table1)
library(knitr)
library(zscorer)
library(stringr)

# Set up paths and read data
# Adjust file paths to match your system
tab_1_person <- read.csv("S:/Sakamoto/Nephrology/Data/Table1 Person Table.csv")
tab_2_encount <- read.csv("S:/Sakamoto/Nephrology/Data/Table2 Encounter Table.csv")
tab_4_labs <- read.csv("S:/Sakamoto/Nephrology/Data/Table 4 Labs.csv")
tab_7_proc <- read.csv("S:/Sakamoto/Nephrology/Data/Table 7 Procedures Table.csv")
tab_8_adt <- read.csv("S:/Sakamoto/Nephrology/Data/Table 8 ADT Table.csv")

# temp tab 3
tab_3_TEMP = read.csv2("S:/Sakamoto/Nephrology/Data/derived datasets/play.csv") %>% select(-X)

```

Step 1: Preparing the Dataset
The dataset AKI_COMPASS_DATA_T1 is loaded from another table (tab_1_person).
Some previously used variables (Diff_DOD and ID_DOD_89) are no longer needed, so they have been removed.

Step 2: Checking for Missing Demographics
A summary table is created to count missing values in key demographic variables like Sex, race, ethnicity, and Death_YN.
Another summary is generated for the DaysDOBtoEpicDeath variable to check:
The total number of records
Missing values
Mean, median, and range (minimum and maximum)

Step 3: Filtering Data for Relevant Patients
The dataset AKI_COMPASS_DATA_T2 is created by selecting only patients from another table (tab_2_encount) who also exist in AKI_COMPASS_DATA_T1.
This ensures that only relevant patients are included in further analyses.

Step 4: Identifying Pediatric Patients
The first recorded encounter for each patient is identified.
Two new flags are created:
FLAG_missing_age: Identifies missing age values.
FLAG_kid_age: Marks patients who are under 18 years old.

Step 5: Checking Baseline Lab Values
The script calculates summary statistics for BaselineResultValue (a key lab measurement).
Patients with extreme or missing values are flagged.

Step 6: Merging Data from Different Tables
Tables 1 and 2 are merged to create the main dataset (analysis).
A new flag is created to identify patients with BaselineResultValue > 8 (indicating potentially abnormal values).
The dataset is filtered to exclude patients who are 18 years or older.

Step 7: Analyzing Lab Data
The dataset AKI_COMPASS_DATA_T4 (lab results) is filtered to include only relevant patients.
Lab data is merged with the main dataset.
Specific lab tests related to Creatinine levels are examined to determine if patients meet certain medical thresholds for acute kidney injury (AKI):
Stage 1: Small increase in creatinine.
Stage 2: Doubling of creatinine levels.
Stage 3: Tripling of creatinine or an extremely high absolute value.
Patients are assigned a Stage (0-3) based on these thresholds.

Step 8: Nephrology Consult Data
The dataset tab_7_proc is filtered to include only patients who had an inpatient nephrology consultation.
This information is merged into the main dataset.

Step 9: Hospital Admissions & Discharges
The dataset tab_8_adt (hospital admissions/discharges) is processed to:
Identify admission and discharge dates for each patient.
Merge these dates into the main dataset.
Calculate whether a patient died during admission.
Calculate how many days passed between discharge and death.
Categorize the time between discharge and death into groups like:
Before discharge
<30 days
30-90 days
1-2 years, etc.

Step 10: Weight, Height, and BMI Calculations
Weight (in ounces) is converted to kilograms.
Height (in inches) is converted to centimeters.
BMI (Body Mass Index) is calculated using weight and height.

Step 11: Categorizing Insurance Types
The payorfinancialclass variable is reformatted into broader insurance categories, such as:
Commercial
Medicaid
Medicare
Indigent Care
Tricare
Self-Pay, etc.

Step 12: Merging Procedure Data
A summary of all procedures performed on each patient is created.
This information is merged into the main dataset for further analysis.
Final Outcome
After completing all these steps, the dataset is cleaned, structured, and ready for further analysis. The dataset now:

Includes only relevant patients.
Flags missing or extreme values.
Categorizes patients based on age, kidney injury stage, and mortality risk.
Merges lab, hospital, and procedure data for a comprehensive view.

```{r dc, include=FALSE}
# Step 1: Initial data setup
AKI_COMPASS_DATA_T1 <- tab_1_person

# Step 2: Derive and clean up variables


# Create Diff_DOD and ID_DOD_89 variables
## THESE DONT EXIST ANYMORE IN CURRENT T1
# AKI_COMPASS_DATA_T1 <- AKI_COMPASS_DATA_T1 %>%
#   mutate(
#     Diff_DOD = abs(Days_from_DOB_to_Epic_DOD - Days_from_DOB_to_CDPHE_DOD),
#     ID_DOD_89 = ifelse(is.na(Days_from_DOB_to_Epic_DOD) & is.na(Days_from_DOB_to_CDPHE_DOD), NA,
#                   ifelse(Days_from_DOB_to_Epic_DOD == "" | Days_from_DOB_to_CDPHE_DOD == "", 1, 0))
#   )


# Step 3: Frequency and descriptive statistics
# Frequency table for missing demographics
freq_table_t1 <- AKI_COMPASS_DATA_T1 %>%
  summarise(across(c(Sex, race, ethnicity, Death_YN), ~sum(is.na(.)))) # none missing 

# Summary statistics for `DaysDOBtoEpicDeath`
summary_stats_t1 <- AKI_COMPASS_DATA_T1 %>%
  summarise(
    n = n(),
    nmiss = sum(is.na(DaysDOBtoEpicDeath)),
    mean = mean(DaysDOBtoEpicDeath, na.rm = TRUE),
    median = median(DaysDOBtoEpicDeath, na.rm = TRUE),
    q1 = quantile(DaysDOBtoEpicDeath, 0.25, na.rm = TRUE),
    q3 = quantile(DaysDOBtoEpicDeath, 0.75, na.rm = TRUE),
    min = min(DaysDOBtoEpicDeath, na.rm = TRUE),
    max = max(DaysDOBtoEpicDeath, na.rm = TRUE)
  )

# Step 4: Filter data for large differences
## THIS OBSOLETE WITH NO MORE CDPHE VAR TO COMPARE
# play_data_365 <- AKI_COMPASS_DATA_T1 %>%
#   filter(Diff_DOD > 365)
# 
# play_data_7 <- AKI_COMPASS_DATA_T1 %>%
#   filter(Diff_DOD > 7)

# Step 5: Subset data for analysis
#AKI_COMPASS_DATA_T2 <- tab_2_encount
AKI_COMPASS_DATA_T2 <- tab_2_encount %>%
  filter(ArbPersonID %in% AKI_COMPASS_DATA_T1$ArbPersonID)

# Step 6: Derive Age-based flags
first <- AKI_COMPASS_DATA_T2 %>%
  arrange(ArbPersonID, AgeDays) %>%
  group_by(ArbPersonID) %>%
  slice(1) %>%
  ungroup()

first_X_age <- first %>%
  mutate(
    FLAG_missing_age = is.na(AgeDays),
    FLAG_kid_age = ifelse(AgeDays <= 6570 & AgeDays > 0, TRUE, FALSE)
  )

# Step 7: Frequency and summary statistics for first age
age_flags_summary <- first_X_age %>%
  summarise(
    missing_age_flag = sum(FLAG_missing_age, na.rm = TRUE),
    kid_age_flag = sum(FLAG_kid_age, na.rm = TRUE)
  )

baseline_summary <- first_X_age %>%
  summarise(
    n = n(),
    nmiss = sum(is.na(BaselineResultValue)),
    mean = mean(BaselineResultValue, na.rm = TRUE),
    median = median(BaselineResultValue, na.rm = TRUE),
    q1 = quantile(BaselineResultValue, 0.25, na.rm = TRUE),
    q3 = quantile(BaselineResultValue, 0.75, na.rm = TRUE),
    min = min(BaselineResultValue, na.rm = TRUE),
    max = max(BaselineResultValue, na.rm = TRUE)
  )

# Step 8: Filter unreasonable BaselineResultValue
over_8 <- first_X_age %>%
  filter(BaselineResultValue > 8)


### COMBINE TABS 1 AND 2 using AKICOMPASS1 and FIRSTXAGE

analysis = full_join(AKI_COMPASS_DATA_T1, first_X_age, by = c("ArbPersonID"))

# add in unreasonable baseline result value flag
analysis = analysis %>% mutate(FLAG_Baselineresultvalue = ifelse(BaselineResultValue > 8 | is.na(BaselineResultValue), TRUE, FALSE))
# sum(analysis$FLAG_Baselineresultvalue) # 3443
# sum(is.na(analysis$BaselineResultValue)) # 3402 -- 41 values above 8

# filter out age 18 and age 0
analysis= analysis%>% filter(FLAG_kid_age == T)

# Step 9: Lab data analysis
AKI_COMPASS_DATA_T4 <- tab_4_labs %>%
  filter(ArbPersonID %in% AKI_COMPASS_DATA_T1$ArbPersonID)
AKI_COMPASS_DATA_T4 = left_join(AKI_COMPASS_DATA_T4,analysis, by=c("ArbPersonID"))

# not calcing well fix after hearing form john on creatine labels to use and how to stage
labs_cr <- AKI_COMPASS_DATA_T4 %>%
  filter(LabCompName %in% c("POCT Creatinine", "Creatinine, Serum/Plasma", "Creatinine Serum/Plasma - U")) %>%
  mutate(
    Stage1_flag = ifelse((DaysFromDOBtoCollection - AgeDays <= 2 & NumericValue - BaselineResultValue >= 0.3) |
                           (DaysFromDOBtoCollection - AgeDays <= 7 & NumericValue / BaselineResultValue >= 1.5), 1, 0),
    Stage2_flag = ifelse(NumericValue / BaselineResultValue >= 2, 1, 0),
    Stage3_flag = ifelse(NumericValue / BaselineResultValue >= 3 | NumericValue >= 4, 1, 0))
    
labs_cr = labs_cr %>% mutate(Stage = case_when(Stage1_flag == 1 ~ 1,
                                               Stage2_flag == 1 ~ 2,
                                               Stage3_flag == 1 ~ 3,
                                               TRUE ~ 0))


# Output frequency of stages
stage_summary <- labs_cr %>%
  group_by(Stage) %>%
  summarise(count = n())

#tables1,2 combined into person + first encounter in "analysis" dataset
####
# COMBINE ANALYSIS AND TABLE 4 HERE
####

# Step 10: Table 7, Nephrology consult

# may need to confirm date happens during admission
tab_7_consult = tab_7_proc %>% filter(ProcedureName == "CONSULT INPT NEPHROLOGY")
analysis = left_join(analysis, tab_7_consult)

# analysis %>% summarise(sum(!is.na(ProcedureName)))

# Step 11: Table 8: Admission, discharge dates etc
# lot of duplicate transfer in/out, lets just look at discharge/admission for now

# create admission and discharge col to easy compare
tab8_adm = tab_8_adt %>% select(ArbPersonID, ArbEncounterID, EventType, DaysFromDOBtoEventdate) %>% filter(EventType %in% c("Admission"))
tab8_dis = tab_8_adt %>% select(ArbPersonID, ArbEncounterID, EventType, DaysFromDOBtoEventdate) %>% filter(EventType %in% c("Discharge"))

tab8_adm_w <- tab8_adm %>% 
  pivot_wider(
    names_from = EventType, 
    values_from = DaysFromDOBtoEventdate,
    values_fn = min
  ) %>%
  mutate(across(where(is.character), ~ na_if(., "NULL"))) %>%
  mutate(across(where(is.character), as.numeric))

tab8_dis_w <- tab8_dis %>% 
  pivot_wider(
    names_from = EventType, 
    values_from = DaysFromDOBtoEventdate,
    values_fn = max
  ) %>%
  mutate(across(where(is.character), ~ na_if(., "NULL"))) %>%
  mutate(across(where(is.character), as.numeric))


# add in to analysis dataset
analysis = left_join(analysis, tab8_adm_w)
analysis = left_join(analysis, tab8_dis_w)

rm(tab8_adm, tab8_adm_w, tab8_dis, tab8_dis_w)
# number of missing admissions/discharge
# sum(is.na(analysis$Admission));sum(is.na(analysis$Discharge))
# create a flag for death at admission n = 16
analysis$FLAG_died_admission <- analysis$Admission == analysis$DaysDOBtoEpicDeath
# sum(analysis$FLAG_died_admission, na.rm = T) 

analysis$death_discharge_days_diff <- analysis$DaysDOBtoEpicDeath - analysis$Discharge

# Categorize the difference
analysis$mortality_after_discharge <- cut(analysis$death_discharge_days_diff,
                                          breaks = c(-Inf,0 , 30, 90, 365, 730, 1825, 3650, Inf),
                                          labels = c("Before Discharge","<30 days", "30-90 days", "90 days-1 year", "1-2 years", "2-5 years", "5-10 years", ">10 years"),
                                          right = FALSE)

####################################
# Table 3 merge in TEMP SPOT IN CODE

tab_3_TEMP$weight_kg = tab_3_TEMP$weight_oz*0.0283495
tab_3_TEMP$height_cm = ifelse(tab_3_TEMP$height_in==0,NA,round(tab_3_TEMP$height_in*2.54,1))

# Define age in months
tab_3_TEMP <- tab_3_TEMP %>%
  mutate(age_months = floor(AgeDays/30))

# Calculate BMI
tab_3_TEMP <- tab_3_TEMP %>%
  mutate(bmi = weight_kg / (height_cm / 100) ^ 2)


analysis = left_join(analysis, tab_3_TEMP)
###################################
# Financial class
analysis = analysis %>% mutate(payorfinancialclass2 = case_when(str_detect(payorfinancialclass, "Commercial") ~ "Commercial",
                                                                str_detect(payorfinancialclass, "Contract") ~ ifelse(str_detect(payorfinancialclass,"Non"), "Non-Contract","Contract"),
                                                                str_detect(payorfinancialclass, "Indigent Care") ~ "Indigent Care",
                                                                str_detect(payorfinancialclass, "Medicaid") ~ "Medicaid",
                                                                str_detect(payorfinancialclass, "Medicare") ~ "Medicare",
                                                                str_detect(payorfinancialclass, "NonContract") ~ "NonContract",
                                                                str_detect(payorfinancialclass, "Other") ~ "Other",
                                                                str_detect(payorfinancialclass, "Tricare") ~ "Tricare",
                                                                str_detect(payorfinancialclass, "Self-Pay") ~ "Self-Pay",
                                                                TRUE ~ NA))


##################################
# TAB 7 merge in TEMP SPOT

tab_7_proc_sum <- tab_7_proc %>%
  group_by(ArbPersonID) %>%
  summarise(ProcedureNames = paste(ProcedureName, collapse = " | ")) %>% select(ArbPersonID, ProcedureNames)

analysis = left_join(analysis, tab_7_proc_sum)
#################################

```

```{r tab 2 7 workspace, include = FALSE}
# tab2 cleaning

## primary admission dx derivation

# examine what we are looking at
# 2944 different categories with 
Dx1 = as.data.frame(table(analysis$PrimaryDx))
# 523 have frequency of 5 or greater. 
# Dx1_g5 = Dx1 %>% filter(Freq >4)

# it looks like a lot of these categories can maybe be compressed using grepl or some sort of string matching function

## financial class

FC1 = as.data.frame(table(analysis$payorfinancialclass))
# this one seems more easy to clean up with a grepl string match -- confirm that this is ok with john



# tab 7 cleaning: 
# look for neph consult in procedures
consult_df = as.data.frame(table(tab_7_proc$ProcedureName))
# looks pretty clear cut -- only one category for neph consult -- double check with John that this makes sense
```

### Questions

#### T2
- how to clean up t2 primary initial diagnosis PrimaryDx

#### T3 
- figure out why zscore program isnt working for casey

#### T7 
- confirm consult is the only category in procedures table, right now we have 24 consults, 13 of which are in our analysis data; correct dataset?

#### T8
- Looks like some values are NULL even in the original dataset; missing 3303 admission dates and 2783 discharge dates. expected?

# DESC TABLES

```{r t12}
#sum(analysis$FLAG_kid_age)
# 15070 out of 18904 had a T flag for kid age (between 1 and 6570 days)
# create t1 with all available vars from/derived the data dictionary
t1_all = table1(~ Sex+ race + ethnicity + height_cm +weight_kg + bmi + BSA_sqm + AgeDays +Hospital + State + payorfinancialclass2  + AKICohortYN + CRRTCohortYN + AKILabYN + 
          AKIDxYN + BaselineResultValue+ DaysDOBtoEpicDeath + Death_YN + FLAG_died_admission + mortality_after_discharge, 
       data = analysis)

t1_all

# death stats
table(analysis$FLAG_died_admission)
table(analysis$mortality_after_discharge)
```

# APPENDIX TABLES

## TOTAL PROCEDURES, T4 LABCOMPNAMES AND PRIMARY DX

```{r appendix}
# all procedures
kable(table(analysis$ProcedureNames))



# labs
kable(table(AKI_COMPASS_DATA_T4$LabCompName))

# 523 have frequency of 5 or greater. 
# Dx1_g5 = Dx1 %>% filter(Freq >4)

kable(table(analysis$PrimaryDx))
```

# T1 Notes

## DERIVED/READY TO PUT IN TABLE AS IS

Age at admission	
Sex (male)	
Race	Race	
Ethnicity	
In state (yes)	
Died (yes) 	
weight
height
bsa
bmi

Died During admission	- derived as FLAG_died_admissions

Mortality after discharge	- now using epic DOD as only var we have now -- derived as 
  30 day		
  90 day		
  1 year		
  2 year		
  5 year		
  10 year
  
## (TAB_3_CLEANING PROGRAM - TODO)

FIGURE OUT ZSCORE PROGRAM


## VARS TO CONFIRM QUESTIONS

Primary admission dx (will need to categorize) PrimaryAdmissionDiagnosis	Table 2 Encounters
Financial Class	FinancialClass	Table 2 Encounters
Nephrology consult	?	Table 7

## VARS TO FIND/DERIVE

ECMO (yes)	?	Table 3? (Daniell emailed asking for this 4.7.2022) - not listed in flowsheet - to derive?

Nephrotoxin	?	Table 5? - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7393580/ - use this to identify exposure to neptox. exposures during hosp

Number		
  1		
  2		
  3		
  .>3	
  
Community acquired AKI, yes		? -- look at lab scr 180 days before admission, during admission and discharge
Time from admission to AKI in those with hospital acquired AKI (? Days or hours)		?
Prior history of KDIGO AKI 	?	?
Stage 1		
Stage 2		
Stage 3		




## NO LONGER EXIST IN CURRENT DATASET

Zip Code	Zip_code_3_digits	Table 2 Encounters
Urban vs suburban		Table 2 Encounters
Distance from CHCO	distance_from_hospital	Table 2 Encounters
  <20 miles		
  20-50 miles		
  50-80 miles		
  80-100		
, >100


## SAS CODE Breakdown:
t1
- the four variables of interest for Table 1 are:
                Sex
                Race
                Ethnicity
                Deceased_yn
- cdphe vs epic dod discrepancy outdated due to no more cdphe dod variable exists
-- similarly no diffdod or dod89 vars
- injury description in appendix (very long)

t2
- only care about IDS in t2 that occur in t1 -- 19375 -> 18904 (matching n with tab1)
- take first age as age at admission, flag between 0 and 6570 (<18yo)
- look at those with baseline values; high baseline values = ~ 41, 3402 missing

t4
- 'POCT Creatinine','Creatinine, Serum/Plasma','Creatinine Serum/Plasma - U' taken from labcomp name(full list in appendix)
- below logic used to code flags using baseline value and lab value
  Stage1_flag = 0;
	Stage2_flag = 0;
	Stage3_flag = 0;
	day = DaysFromDOBtoCollection - AgeDays ;
	diff_scr = NumericValue - BaselineResultValue;
	ratio_scr = NumericValue/BaselineResultValue;

	IF Day <=2 Then DO;
	   if diff_scr >=0.3 THEN Stage1_flag = 1;
	END;
	IF Day <=7 THen Do;
		if ratio_scr >=1.5 THEN Stage1_flag = 1;
	END;

		if ratio_scr >=2 THEN Stage2_flag = 1;

		if ratio_scr >=3 THEN Stage3_flag = 1;
		if NumericValue>=4 THEN Stage3_flag = 1;

Stage = 0;
IF (Stage1_flag) THEN STAGE = 1;
IF (Stage2_flag) THEN STAGE = 2;
IF (Stage3_flag) THEN STAGE = 3;

- 
